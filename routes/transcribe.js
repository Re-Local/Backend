const express = require('express');
const router = express.Router();
const OpenAI = require('openai');
const multer = require('multer');
const fs = require('fs');
const path = require('path');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// ðŸ“ ì—…ë¡œë“œ ì„¤ì •
const uploadDir = path.join(__dirname, '../uploads');
if (!fs.existsSync(uploadDir)) fs.mkdirSync(uploadDir);
const storage = multer.diskStorage({
  destination: (_req, _file, cb) => cb(null, uploadDir),
  filename: (_req, file, cb) => {
    const ext = path.extname(file.originalname) || '.mp3';
    cb(null, `${Date.now()}${ext}`);
  },
});
const upload = multer({ storage });

/**
 * @openapi
 * /api/transcribe/stt:
 *   post:
 *     summary: "ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (STT)"
 *     tags: [Transcribe]
 *     requestBody:
 *       required: true
 *       content:
 *         multipart/form-data:
 *           schema:
 *             type: object
 *             properties:
 *               audio:
 *                 type: string
 *                 format: binary
 *     responses:
 *       200:
 *         description: í…ìŠ¤íŠ¸ ë°˜í™˜
 */
router.post('/stt', upload.single('audio'), async (req, res) => {
  console.log('req.file:', req.file);
  console.log('req.body:', req.body);

  const filePath = req.file?.path;
  if (!filePath) return res.status(400).json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.' });

  try {
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(filePath),
      model: 'whisper-1',
      response_format: 'text',
    });
    res.json({ text: transcription });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: 'STT ì‹¤íŒ¨', detail: err.message });
  } finally {
    if (filePath && fs.existsSync(filePath)) fs.unlinkSync(filePath);
  }
});

/**
 * @openapi
 * /api/transcribe/sts:
 *   get:
 *     summary: "ì €ìž¥ëœ ìŒì„± íŒŒì¼ë¡œë¶€í„° ìžë™ ë²ˆì—­ ìŒì„±ì„ ìƒì„± (STT â†’ ë²ˆì—­ â†’ TTS)"
 *     tags: [Transcribe]
 *     parameters:
 *       - in: query
 *         name: filename
 *         required: true
 *         schema:
 *           type: string
 *         description: "ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ ì´ë¦„ìž…ë‹ˆë‹¤. ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: /sts?filename=1692603423.mp3)"

 *     responses:
 *       200:
 *         description: "ë²ˆì—­ëœ ìŒì„± mp3 ë°˜í™˜"
 *         content:
 *           audio/mpeg:
 *             schema:
 *               type: string
 *               format: binary
 */
router.get('/sts', async (req, res) => {
  const { filename } = req.query;
  if (!filename) {
    return res.status(400).json({ error: 'filename ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.' });
  }

  const filePath = path.join(uploadDir, filename);
  if (!fs.existsSync(filePath)) {
    return res.status(404).json({ error: 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' });
  }

  try {
    // 1. STT
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(filePath),
      model: 'whisper-1',
      response_format: 'text',
    });
    const originalText = transcription;

    // 2. ì–¸ì–´ ê°ì§€
    const isKorean = /[ê°€-íž£]/.test(originalText);
    const targetLang = isKorean ? 'en' : 'ko';

    // 3. ë²ˆì—­
    const prompt = `ë‹¤ìŒ ë¬¸ìž¥ì„ ${targetLang}ë¡œ ë²ˆì—­í•´ì¤˜:\n"${originalText}"`;
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: prompt }],
    });
    const translatedText = completion.choices[0].message.content;

    // 4. TTS
    const tts = await openai.audio.speech.create({
      model: 'tts-1-hd',
      voice: targetLang === 'ko' ? 'nova' : 'shimmer',
      input: translatedText,
      response_format: 'mp3',
    });

    const buffer = Buffer.from(await tts.arrayBuffer());
    res.set('Content-Type', 'audio/mpeg');
    res.set('Content-Disposition', 'inline; filename="translated.mp3"');
    res.send(buffer);
  } catch (err) {
    console.error('STS Error:', err);
    res.status(500).json({ error: 'STS ì‹¤íŒ¨', detail: err.message });
  }
});


/**
 * @openapi
 * /api/transcribe/tt:
 *   post:
 *     summary: "í…ìŠ¤íŠ¸ ë²ˆì—­ (TT)"
 *     tags: [Transcribe]
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               text:
 *                 type: string
 *                 example: "ì•ˆë…•í•˜ì„¸ìš”"
 *               targetLang:
 *                 type: string
 *                 example: "en"
 *     responses:
 *       200:
 *         description: ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ë°˜í™˜
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 translated:
 *                   type: string
 *                   example: "Hello"
 */



// ðŸ“„ routes/transcribe.js ì•ˆì— ì¶”ê°€ (ë˜ëŠ” ë¶„ë¦¬í•´ì„œ ì¨ë„ ë¨)
router.post('/tt', async (req, res) => {
  const { text, targetLang = 'en' } = req.body;

  if (!text) {
    return res.status(400).json({ error: 'textëŠ” í•„ìˆ˜ìž…ë‹ˆë‹¤.' });
  }

  try {
    const prompt = `ë‹¤ìŒ ë¬¸ìž¥ì„ ${targetLang}ë¡œ ë²ˆì—­í•´ì¤˜:\n"${text}"`;

    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: prompt }],
    });

    const translated = completion.choices[0].message.content;
    res.json({ translated });
  } catch (err) {
    console.error('TT Error:', err);
    res.status(500).json({ error: 'TT ì‹¤íŒ¨', detail: err.message });
  }
});


/**
 * @openapi
 * /api/transcribe/tts:
 *   post:
 *     summary: "í…ìŠ¤íŠ¸ â†’ ìŒì„± ë³€í™˜ (TTS)"
 *     tags: [Transcribe]
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               text:
 *                 type: string
 *                 example: "ì•ˆë…•í•˜ì„¸ìš”"
 *               language:
 *                 type: string
 *                 enum: [ko, en]
 *                 example: "ko"
 *     responses:
 *       200:
 *         description: ìƒì„±ëœ ìŒì„± mp3 ë°˜í™˜
 *         content:
 *           audio/mpeg:
 *             schema:
 *               type: string
 *               format: binary
 */
router.post('/tts', async (req, res) => {
  const { text, language = 'ko' } = req.body;
  if (!text) return res.status(400).json({ error: 'textê°€ í•„ìš”í•©ë‹ˆë‹¤.' });

  try {
    const tts = await openai.audio.speech.create({
      model: 'tts-1-hd',
      voice: language === 'ko' ? 'nova' : 'shimmer',
      input: text,
      response_format: 'mp3',
    });

    const buffer = Buffer.from(await tts.arrayBuffer());
    res.set('Content-Type', 'audio/mpeg');
    res.set('Content-Disposition', 'inline; filename="tts.mp3"');
    res.send(buffer);
  } catch (err) {
    console.error('TTS Error:', err);
    res.status(500).json({ error: 'TTS ì‹¤íŒ¨', detail: err.message });
  }
});

module.exports = router;
